{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\learnx.ai\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq, T5ForConditionalGeneration, AdamW, get_scheduler, DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_source_length = 512\n",
    "max_target_length = 128\n",
    "prefix_1 = \"answer: \"\n",
    "prefix_2 = \" context: \"\n",
    "prefix_3 = \"question: \"\n",
    "checkpoint = \"t5-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "  input_1 = [ prefix_1 + i[0] for i in examples[\"answers.text\"] ]\n",
    "  input_2 = [ prefix_2 + i for i in examples[\"context\"] ]\n",
    "  input = [input_1[i] + input_2[i] for i in range(len(examples[\"context\"]))]\n",
    "  inputs = [input[0] for i in range(len(examples[\"context\"]))]\n",
    "  model_inputs = tokenizer(inputs, padding=\"longest\", max_length = max_source_length , truncation = True, return_tensors = \"pt\")\n",
    "  labels = tokenizer([prefix_3 + i for i in examples[\"question\"]], padding=\"longest\", max_length = max_target_length ,truncation = True, return_tensors = \"pt\")\n",
    "  labels[\"input_ids\"][labels[\"input_ids\"]==tokenizer.pad_token_id] = -100\n",
    "  model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "  return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Saint Bernadette Soubirous']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad = load_dataset(\"squad\")\n",
    "squad = squad.flatten()\n",
    "squad[\"train\"][0][\"answers.text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_tokenized = squad.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_tokenized = squad_tokenized.remove_columns([\"id\",\"title\",\"question\",\"context\",\"answers.text\",\"answers.answer_start\"])\n",
    "squad_tokenized.set_format(\"torch\")\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer, model = checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(squad_tokenized[\"train\"], batch_size=8, collate_fn=data_collator)\n",
    "eval_dataloader = DataLoader(squad_tokenized[\"validation\"], batch_size=8, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': torch.Size([8, 192]), 'attention_mask': torch.Size([8, 192]), 'labels': torch.Size([8, 41])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\learnx.ai\\.venv\\lib\\site-packages\\transformers\\data\\data_collator.py:656: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
      "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "print({k:v.shape for k,v in batch.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: Saint Bernadette Soubirous context: Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.</s>\n",
      "question: To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "  break\n",
    "print(tokenizer.decode(batch[\"input_ids\"][0]))\n",
    "fake_labels = np.where(batch[\"labels\"][0]!=-100, batch[\"labels\"][0], tokenizer.pad_token_id)\n",
    "print(tokenizer.decode(fake_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2687, grad_fn=<NllLossBackward0>) torch.Size([8, 41, 32128])\n"
     ]
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(checkpoint)\n",
    "outputs = model(**batch)\n",
    "print(outputs.loss, outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10950"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\learnx.ai\\.venv\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "loss = outputs.loss\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "# model.train()\n",
    "# for epoch in range(num_epochs):\n",
    "#   for batch in train_dataloader:\n",
    "#     batch = {k:v.to(device) for k,v in batch.items()}\n",
    "#     outputs = model(**batch)\n",
    "#     loss = outputs.loss\n",
    "#     loss.backward()\n",
    "\n",
    "#     optimizer.step()\n",
    "#     lr_scheduler.step()\n",
    "#     optimizer.zero_grad()\n",
    "#     progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"t5_question_generation_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.wsd import lesk\n",
    "from nltk.corpus import stopwords, wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from rake_nltk import Rake, Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\learnx.ai\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "squad = load_dataset(\"squad\")\n",
    "text = squad[\"train\"][\"context\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rake_nltk = Rake(max_length=3, \n",
    "                include_repeated_phrases = False)\n",
    "\n",
    "rake_nltk.extract_keywords_from_text(text)\n",
    "keywords = rake_nltk.get_ranked_phrases()\n",
    "\n",
    "filtered_keywords = set()\n",
    "#punctuation removal from the text followed\n",
    "for i in keywords:\n",
    "    i = i.translate(str.maketrans(\"\",\"\",string.punctuation)).strip()\n",
    "    filtered_keywords.add(i)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sample = random.sample(filtered_keywords, 5)\n",
    "masked_sentence = []\n",
    "cased_keywords = ([(i.upper(), i.lower(), i.capitalize(), i.title()) for i in sample])\n",
    "temp = text\n",
    "\n",
    "for i,j,k,l in cased_keywords:\n",
    "  temp = temp.replace(i,\"[MASK]\").replace(j,\"[MASK]\").replace(k,\"[MASK]\").replace(l,\"[MASK]\")\n",
    "\n",
    "for i in nltk.sent_tokenize(temp):\n",
    "  if \"[MASK]\" in i:\n",
    "    masked_sentence.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          Atop the Main Building's [MASK] is a golden statue of the Virgin Mary.\n",
      "1          Immediately behind the basilica is the Grotto, a [MASK] of [MASK] and reflection.\n",
      "2          It is a [MASK] of the grotto at [MASK], France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858.\n",
      "3          At the end of the main drive (and in a direct line that connects through 3 statues and the [MASK]), is a simple, modern stone statue of Mary.\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(masked_sentence):\n",
    "    print(\"{:}{:10}{:}\".format(i,\" \",j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keyword extraction using rake-nltk\n",
    "rake_nltk = Rake(max_length = 1, \n",
    "                include_repeated_phrases = False,\n",
    "                punctuations = string.punctuation)\n",
    "\n",
    "rake_nltk.extract_keywords_from_text(text)\n",
    "keywords = rake_nltk.get_ranked_phrases()[:10]\n",
    "\n",
    "#punctuation and stopwords removal from the text followed by lemmatization\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "text_no_punc = text.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "word_tokens = word_tokenize(text_no_punc.lower())\n",
    "#filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_sentence = [lemmatizer.lemmatize(w) for w in word_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_keywords = []\n",
    "wn_definitions = []\n",
    "try:\n",
    "    for i in keywords:\n",
    "        wn_keywords.append(i)\n",
    "        wn_definitions.append(lesk(lemmatized_sentence, i).definition())\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replica                                                                                             a person lacking intelligence or common sense\n",
      "mary                                                                                                the period of instruction in a school; the time period when school is in session\n",
      "next                                                                                                copy that is not the original; something that has been copied\n",
      "simple                                                                                              (mathematics) a transformation in which the direction of one axis is reversed\n",
      "prayer                                                                                              the act of communicating with a deity (especially as a petition or in adoration or contrition or thanksgiving)\n",
      "lourdes                                                                                             at the time or occasion immediately following\n",
      "reflection                                                                                          the mother of Jesus; Christians refer to her as the Virgin Mary; she is especially honored by Roman Catholics\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "sample = random.sample(wn_keywords, len(wn_keywords)-1)\n",
    "try:\n",
    "    for i in range(len(sample)):\n",
    "        print(\"{:100}{:10}\".format(sample[i], wn_definitions[i]))\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BertForPreTraining\n",
    "\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = BertForPreTraining.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in d:\\learnx.ai\\.venv\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in d:\\learnx.ai\\.venv\\lib\\site-packages (from gensim) (1.24.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in d:\\learnx.ai\\.venv\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in d:\\learnx.ai\\.venv\\lib\\site-packages (from gensim) (7.0.4)\n",
      "Requirement already satisfied: wrapt in d:\\learnx.ai\\.venv\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
